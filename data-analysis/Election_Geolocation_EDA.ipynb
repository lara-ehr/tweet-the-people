{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Election Tweets: Geolocation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To understand just how real the \"red state/blue state\" divide is on the tweet level, I need some geolocation data. Since only very few users (<2%) activate the geotagging feature on their user accounts, I'll need to get this information from other sources. I decided to extract this info from people's self-reported location (in their user profile), but now I want to see what the data looks like and what information I can extract to put towards modelling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = pd.read_csv('/Users/laraehrenhofer/Documents/Coding_Projects/git_repos/tweet-the-people-legacy/data/tweet_pg.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Understanding geolocation by numbers\n",
    "\n",
    "Some introductory questions:\n",
    "- How many tweets have geotagged location vs. location based on profile info?\n",
    "- Any differences by Republican/Democrat ticket?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Geotagged vs. profile geolocation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some basic cleanup is necessary as some of these locations were generated in development versions of the tweet streaming script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_no = pd.DataFrame(tweets.groupby(['loc_type', 'ticket']).count()['tweet_id']).unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_rows = ['bound_box_coords', 'no_loc', 'user_loc']\n",
    "drop_rows = [column for column in loc_no.index.values if column not in keep_rows]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_no = loc_no.drop(drop_rows, axis=0)\n",
    "loc_no = pd.DataFrame(loc_no.to_records())\n",
    "loc_no.columns = ['loc_type', 'Democrat', 'Republican']\n",
    "loc_no['total'] = loc_no['Democrat'] + loc_no['Republican']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ticket_percent(data, ticket):\n",
    "    colname_total = f'percent_of_total_{ticket}'\n",
    "    colname_ticket = f'percent_of_ticket_{ticket}'\n",
    "    data[colname_total] = data[ticket].apply(lambda x: round((x/sum(data['total']))*100, 2))\n",
    "    data[colname_ticket] = data[ticket].apply(lambda x: round((x/sum(data[ticket]))*100, 2))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickets = ['Democrat', 'Republican']\n",
    "\n",
    "for ticket in tickets:\n",
    "    loc_no = get_ticket_percent(loc_no, ticket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_no['total_percent'] = loc_no['total'].apply(lambda x: round((x/sum(loc_no['total']))*100, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loc_type</th>\n",
       "      <th>Democrat</th>\n",
       "      <th>Republican</th>\n",
       "      <th>total</th>\n",
       "      <th>percent_of_total_Democrat</th>\n",
       "      <th>percent_of_ticket_Democrat</th>\n",
       "      <th>percent_of_total_Republican</th>\n",
       "      <th>percent_of_ticket_Republican</th>\n",
       "      <th>total_percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bound_box_coords</td>\n",
       "      <td>851.0</td>\n",
       "      <td>401.0</td>\n",
       "      <td>1252.0</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>no_loc</td>\n",
       "      <td>78283.0</td>\n",
       "      <td>50747.0</td>\n",
       "      <td>129030.0</td>\n",
       "      <td>24.75</td>\n",
       "      <td>41.53</td>\n",
       "      <td>16.04</td>\n",
       "      <td>39.70</td>\n",
       "      <td>40.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>user_loc</td>\n",
       "      <td>109385.0</td>\n",
       "      <td>76665.0</td>\n",
       "      <td>186050.0</td>\n",
       "      <td>34.58</td>\n",
       "      <td>58.02</td>\n",
       "      <td>24.24</td>\n",
       "      <td>59.98</td>\n",
       "      <td>58.81</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           loc_type  Democrat  Republican     total  \\\n",
       "0  bound_box_coords     851.0       401.0    1252.0   \n",
       "1            no_loc   78283.0     50747.0  129030.0   \n",
       "2          user_loc  109385.0     76665.0  186050.0   \n",
       "\n",
       "   percent_of_total_Democrat  percent_of_ticket_Democrat  \\\n",
       "0                       0.27                        0.45   \n",
       "1                      24.75                       41.53   \n",
       "2                      34.58                       58.02   \n",
       "\n",
       "   percent_of_total_Republican  percent_of_ticket_Republican  total_percent  \n",
       "0                         0.13                          0.31           0.40  \n",
       "1                        16.04                         39.70          40.79  \n",
       "2                        24.24                         59.98          58.81  "
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loc_no"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusions\n",
    "\n",
    "1. Less than half a percent of this tweet database has 'ground-truth' geotagged location data.\n",
    "2. 40% has no location at all.\n",
    "3. But between geotagging and user profile location data, we still have close to 60% of the dataset available.\n",
    "4. Initially it looks like there's a partisan divide in terms of people's provision of geolocation data (looking at the `percent_of_total` columns). However, breaking it down into percent by ticket suggests that there isn't an enormous contrast between the two populations after all, this is just an artefact of there being slightly more Democrat than Republican tweets overall. (Could determine further statistical information concerning probability of having a location based on ticket using a logistic regression here but it doesn't seem interesting enough to warrant the extra attention.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Quality check\n",
    "\n",
    "I used the `geocoder` package to get over 42k locations based on people's user profiles. While some folks' self-reported location is plausible (\"Milwaukee-Chicago\"), other locations are less straightforward to map onto real-world locations (\"Marvel Universe\", \"hell since 2016\", \"God's Country\", \"Always butter the Pan\"). What did `geocoder` make of these less plausible locations?\n",
    "\n",
    "How to check: Sample 1000 locations and manually check. (I want a GUI for this and am doing it in good old Excel.)\n",
    "- What proportion of these is a joke location? This will help us get a sense of the amount of noise in the data.\n",
    "- What does `geocoder` make of the joke locations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45219"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_locs = list(tweets['location'].unique())\n",
    "len(list_locs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate out just the tweets that have a profile-based location\n",
    "\n",
    "loc_tweets = tweets[tweets['location'] == 'user_loc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_sample = loc_tweets.sample(n=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_sample = loc_sample.drop([column for column in loc_sample.columns if column not in ['location', 'loc_type', 'us_state', 'loc_lat', 'loc_lon']], axis=1)\n",
    "loc_sample.to_csv('./location_random_sample.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Manual data annotation of random sample:**\n",
    "\n",
    "1. Binary manual classification into feature `unclear_loc` (0, 1). Some examples of `unclear_loc == 1` in this particular sample:\n",
    "    - a `location: Right now? Arkansas`\n",
    "    - b `Earth`\n",
    "    - c `In Trump's Nightmares`\n",
    "    - d `COviNGTON va BAbY!!!!`\n",
    "    - e `Nicht Bielefeld`\n",
    "    - f `None of your business`\n",
    "    - g `NoVa`\n",
    "    - h `The Dirty South-GA`\n",
    "2. Binary manual classification into feature `implausible_assigned_loc` (0, 1). My highly subjective criteria were:\n",
    "    - `implausible_assigned_loc == 0`: if `geocoder` managed to get correct information out of an unclear location (e.g. assigning location `Arkansas` to example a, `Virginia` to example d), or classifies it as `other` (e.g. assigning `other` to example e).\n",
    "    - `implausible_assigned_loc == 1`: odder assignments get a rating of 1, e.g. assigning location b to Texas, c to Maryland, f to Washington, or g to Ohio (\"NoVa\" is short for Northern Virginia), or failing to get location information where technically present (e.g. assigning `other` to example h).\n",
    "    \n",
    "**Next up:** let's get a sense of the scale of the noise.\n",
    "1. What percentage of locations are unclear?\n",
    "2. Of these, what percentage are implausible and therefore likely erroneous?\n",
    "3. What's the likely percentage of erroneous assignments overall?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_sample_annotated = pd.read_csv('./location_random_sample_13012021.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "loc_lat                     float64\n",
       "loc_lon                     float64\n",
       "loc_type                     object\n",
       "location                     object\n",
       "us_state                     object\n",
       "unclear_loc                   int64\n",
       "implausible_assigned_loc      int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loc_sample_annotated.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18.410462776659962"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "percent_unclear = (sum(loc_sample_annotated['unclear_loc'])/len(loc_sample_annotated))*100\n",
    "percent_unclear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44.80874316939891"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "percent_implausible = (sum(loc_sample_annotated['implausible_assigned_loc'])/len(loc_sample_annotated[loc_sample_annotated['unclear_loc'] == 1]))*100\n",
    "percent_implausible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.249496981891348"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "percent_erroneous_total = (sum(loc_sample_annotated['implausible_assigned_loc'])/len(loc_sample_annotated))*100\n",
    "percent_erroneous_total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusions from manual data quality check\n",
    "\n",
    "In this sample, nearly one-fifth of locations were unclear; just under half of those were not assigned a correct location by `geocoder`. Overall, this results in a ca. 8% rate of poor location information.\n",
    "\n",
    "This is pretty rough news, as it means there's quite a lot of noise in the geolocation data!\n",
    "\n",
    "**How to get around this?**\n",
    "\n",
    "Options from various domains (which could also help impute missing location data for the users who provided none at all):\n",
    "\n",
    "1. **Hashtag tracking:** If the tweet contains a hashtag, in which state is this hashtag most popular?\n",
    "    - Conditional probabilities/TF-IDF: given a particular hashtag, what's the likelihood of it being tweeted from a specific state?\n",
    "    - Use a Bayesian model to predict state from hashtag?\n",
    "        - This is risky as the model will be learning from poorly labelled (noisy) data.\n",
    "        - Are there enough geotagged tweets containing hashtags in order to build a Bayesian model restricted to just this data subset, and then extrapolate from there to the wider dataset?\n",
    "        - Benchmark model performance on the ground-truthed, human-annotated reference sample; if performance is reasonable, apply to the rest of the dataset\n",
    "    \n",
    "2. **Social network clustering:** Can we interpolate a user's location from the people they follow and their locations?\n",
    "    - The dataset contains tweets from >220k unique users\n",
    "    - Steps would be:\n",
    "        - Grab user's followed accounts (Twitter API limits this to 5k followers at a time, this seems like more than enough)\n",
    "        - Get those users' locations where possible (this will have the same problem with noise in self-reported locations)\n",
    "        - Interpolation: copy location of the account that a user most frequently interacts with? Does Twitter provide this data in some summary form? If so, is the location of a high-interaction account actually a good proxy for a user's location? (Boils down to: do people interact more with people who live close to them? Probably some do and some don't.)\n",
    "        \n",
    "        \n",
    "I'm going to try hashtag tracking first."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Location Interpolation -- Conditional probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
